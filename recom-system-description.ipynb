{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Recommendation system by description with natural language processing\n\nIn the notebook a recommendation system if presented which proposes similar movies by their description. The descriptions of the movies are converted to a vector, and the cosine similarity between the description vectors give back the most similar movies (clearly, based only on the description) - for more about cosine similary see the notebook which uses cosine similarity for prediction.  \n\nFor converting the descriptions into vector the Doc2Vec algorithm is used, which is a deep learning algorithm, designed for tasks like these: forms vectors from documents and if the cosine similarities of the vectors are higher the documents are more similar. It builds strongly on the Word2Vec algorithm, which does the same, but only for words.\n\n![](https://miro.medium.com/max/1400/1*9tVCGDm-ytPydhtJWVx3Zw.png)","metadata":{}},{"cell_type":"markdown","source":"## Preprocessing\n\nUsed libraries:\n* numpy : for linear algebra calculation\n* pandas : for csv/dataframe manipulation\n* nltk : for natural language preprocessing functions like stopword removal, stemming, tokenization\n* gensim : for Doc2Vec algorithm\n* cosine_similarity : for cos sim calculation\n* plt : for plotting diagrams","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport re\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\n\nfrom gensim.test.utils import common_texts\nfrom gensim.models.doc2vec import Doc2Vec, TaggedDocument\n\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-13T19:31:03.009323Z","iopub.execute_input":"2021-12-13T19:31:03.009911Z","iopub.status.idle":"2021-12-13T19:31:05.246822Z","shell.execute_reply.started":"2021-12-13T19:31:03.009814Z","shell.execute_reply":"2021-12-13T19:31:05.245543Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Used datas:\n* df_movies : dataframe of movies\n* df_ratings : dataframe of ratings\n* useful_links_df : contains only the movies, for which the descriptions were scraped\n* df : dataframe of descriptions\n\nWe need the ratings, because as in the case of matrix factorization and in the case of the poster similarity calulcation we use only the most popular datas, as the scraping would have taken too much time if we wanted to scrape the descriptions for all of the movies. ","metadata":{}},{"cell_type":"code","source":"df_links = pd.read_csv(\"/kaggle/input/movielens-25m-dataset/ml-25m/links.csv\")\ndf_movies = pd.read_csv(\"/kaggle/input/movielens-25m-dataset/ml-25m/movies.csv\")\nratings_df = pd.read_csv(\"/kaggle/input/movielens-25m-dataset/ml-25m/ratings.csv\")\nratings_df.drop(columns = [\"timestamp\"], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T16:22:46.754836Z","iopub.execute_input":"2021-12-12T16:22:46.755051Z","iopub.status.idle":"2021-12-12T16:23:04.083693Z","shell.execute_reply.started":"2021-12-12T16:22:46.755025Z","shell.execute_reply":"2021-12-12T16:23:04.082865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_links = df_links.merge(df_movies, on=\"movieId\")\ndf_links.fillna(0, inplace=True)\ndf_links[\"tmdbId\"] = df_links[\"tmdbId\"].astype(int)\ndf_links\n\nratings_df[\"movie_freq\"] = ratings_df.groupby(\"movieId\")[\"movieId\"].transform('count')\nMOVIE_FREQ_LIMIT = 500\nratings_df = ratings_df.loc[(ratings_df[\"movie_freq\"] > MOVIE_FREQ_LIMIT)]\nmost_popular_film_ids = ratings_df[\"movieId\"].unique()\nmost_popular_film_ids.sort()\nuseful_links_df = df_links.loc[df_links[\"movieId\"].isin(most_popular_film_ids)]\nuseful_links_df = useful_links_df.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T16:23:04.084825Z","iopub.execute_input":"2021-12-12T16:23:04.085417Z","iopub.status.idle":"2021-12-12T16:23:06.337146Z","shell.execute_reply.started":"2021-12-12T16:23:04.085378Z","shell.execute_reply":"2021-12-12T16:23:06.336131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"useful_links_df = useful_links_df.drop([1816, 2511, 3459, 3643, 3707, 4050, 4327, 4698, 4947, 5086, 5088, 5109, 5167])","metadata":{"execution":{"iopub.status.busy":"2021-12-12T16:23:06.338361Z","iopub.execute_input":"2021-12-12T16:23:06.338604Z","iopub.status.idle":"2021-12-12T16:23:06.345385Z","shell.execute_reply.started":"2021-12-12T16:23:06.338574Z","shell.execute_reply":"2021-12-12T16:23:06.344341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"useful_links_df = useful_links_df.reset_index(drop=True)\nuseful_links_df = useful_links_df.head(5155)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T16:23:06.347641Z","iopub.execute_input":"2021-12-12T16:23:06.347995Z","iopub.status.idle":"2021-12-12T16:23:06.357144Z","shell.execute_reply.started":"2021-12-12T16:23:06.347962Z","shell.execute_reply":"2021-12-12T16:23:06.356391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"useful_links_df.loc[useful_links_df[\"title\"].str.contains(\"Star\")]","metadata":{"execution":{"iopub.status.busy":"2021-12-12T16:27:30.91901Z","iopub.execute_input":"2021-12-12T16:27:30.919969Z","iopub.status.idle":"2021-12-12T16:27:30.939975Z","shell.execute_reply.started":"2021-12-12T16:27:30.919917Z","shell.execute_reply":"2021-12-12T16:27:30.939374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/movie-reviews/descriptions-2.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-12-12T16:23:06.391209Z","iopub.execute_input":"2021-12-12T16:23:06.391419Z","iopub.status.idle":"2021-12-12T16:23:06.442048Z","shell.execute_reply.started":"2021-12-12T16:23:06.391393Z","shell.execute_reply":"2021-12-12T16:23:06.441316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"vector\"] = \"\"\ndf","metadata":{"execution":{"iopub.status.busy":"2021-12-12T16:23:06.443661Z","iopub.execute_input":"2021-12-12T16:23:06.443973Z","iopub.status.idle":"2021-12-12T16:23:06.461863Z","shell.execute_reply.started":"2021-12-12T16:23:06.443931Z","shell.execute_reply":"2021-12-12T16:23:06.46102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"proba_description = df.iloc[0,1]\nproba_description","metadata":{"execution":{"iopub.status.busy":"2021-12-12T16:23:06.463366Z","iopub.execute_input":"2021-12-12T16:23:06.464007Z","iopub.status.idle":"2021-12-12T16:23:06.470103Z","shell.execute_reply.started":"2021-12-12T16:23:06.463961Z","shell.execute_reply":"2021-12-12T16:23:06.469273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Function for cleaning the sentence. The following preprocessings are done:\n* remove non-alphanumeric character\n* tokenization of sentences\n* stop word removal\n* lemmatization of words","metadata":{}},{"cell_type":"code","source":"def clean_sentence(description_text):\n    #remove non-alphabetic characters\n    description_text = re.sub(\"[^a-zA-Z]\",\" \", description_text)\n\n    #tokenize the sentences\n    description_tokens = word_tokenize(description_text.lower())\n\n    #stop words removal\n    omit_words = set(stopwords.words('english'))\n    words = [x for x in description_tokens if x not in omit_words]\n\n    #lemmatize each word to its lemma\n    lemma_words = [WordNetLemmatizer().lemmatize(i) for i in words]\n\n    return lemma_words","metadata":{"execution":{"iopub.status.busy":"2021-12-12T16:23:06.471589Z","iopub.execute_input":"2021-12-12T16:23:06.472156Z","iopub.status.idle":"2021-12-12T16:23:06.481413Z","shell.execute_reply.started":"2021-12-12T16:23:06.472113Z","shell.execute_reply":"2021-12-12T16:23:06.48066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmdb_ids = df[\"tmdb_id\"].tolist()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T16:23:06.483132Z","iopub.execute_input":"2021-12-12T16:23:06.48368Z","iopub.status.idle":"2021-12-12T16:23:06.497654Z","shell.execute_reply.started":"2021-12-12T16:23:06.483639Z","shell.execute_reply":"2021-12-12T16:23:06.496882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cleaned_reviews = []","metadata":{"execution":{"iopub.status.busy":"2021-12-12T16:23:06.498938Z","iopub.execute_input":"2021-12-12T16:23:06.499511Z","iopub.status.idle":"2021-12-12T16:23:06.510921Z","shell.execute_reply.started":"2021-12-12T16:23:06.49947Z","shell.execute_reply":"2021-12-12T16:23:06.51022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(df)):\n    cleaned_reviews.append(clean_sentence(df.iloc[i, 1]))","metadata":{"execution":{"iopub.status.busy":"2021-12-12T16:23:06.512255Z","iopub.execute_input":"2021-12-12T16:23:06.512707Z","iopub.status.idle":"2021-12-12T16:23:14.046805Z","shell.execute_reply.started":"2021-12-12T16:23:06.512674Z","shell.execute_reply":"2021-12-12T16:23:14.045883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After the basic NLP preprocessings, in the documents variable the descriptions are brought to the format, which are accepted by the Doc2Vec algorithm. ","metadata":{}},{"cell_type":"code","source":"documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(cleaned_reviews)]","metadata":{"execution":{"iopub.status.busy":"2021-12-12T16:23:14.049653Z","iopub.execute_input":"2021-12-12T16:23:14.0499Z","iopub.status.idle":"2021-12-12T16:23:14.062247Z","shell.execute_reply.started":"2021-12-12T16:23:14.049867Z","shell.execute_reply":"2021-12-12T16:23:14.061255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"markdown","source":"Run the Doc2Vec model","metadata":{}},{"cell_type":"code","source":"model = Doc2Vec(documents, vector_size=300, min_count=2, epochs=40, window=2)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T16:23:14.063581Z","iopub.execute_input":"2021-12-12T16:23:14.063903Z","iopub.status.idle":"2021-12-12T16:23:42.731255Z","shell.execute_reply.started":"2021-12-12T16:23:14.063859Z","shell.execute_reply":"2021-12-12T16:23:42.730158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectors = []","metadata":{"execution":{"iopub.status.busy":"2021-12-12T16:23:42.733469Z","iopub.execute_input":"2021-12-12T16:23:42.734327Z","iopub.status.idle":"2021-12-12T16:23:42.73941Z","shell.execute_reply.started":"2021-12-12T16:23:42.734276Z","shell.execute_reply":"2021-12-12T16:23:42.738451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create list from predictions","metadata":{}},{"cell_type":"code","source":"for i in range(len(df)):\n    vector = model.infer_vector(documents[i][0])\n    vectors.append(vector.tolist())","metadata":{"execution":{"iopub.status.busy":"2021-12-12T16:23:42.740868Z","iopub.execute_input":"2021-12-12T16:23:42.741213Z","iopub.status.idle":"2021-12-12T16:24:06.838724Z","shell.execute_reply.started":"2021-12-12T16:23:42.74117Z","shell.execute_reply":"2021-12-12T16:24:06.837946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Calculate cosine similarity","metadata":{}},{"cell_type":"code","source":"cosine_sim = cosine_similarity(vectors)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T16:24:06.840053Z","iopub.execute_input":"2021-12-12T16:24:06.840452Z","iopub.status.idle":"2021-12-12T16:24:07.373341Z","shell.execute_reply.started":"2021-12-12T16:24:06.840412Z","shell.execute_reply":"2021-12-12T16:24:07.37252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{"execution":{"iopub.status.busy":"2021-12-03T20:09:26.197451Z","iopub.execute_input":"2021-12-03T20:09:26.197717Z","iopub.status.idle":"2021-12-03T20:09:26.200947Z","shell.execute_reply.started":"2021-12-03T20:09:26.19769Z","shell.execute_reply":"2021-12-03T20:09:26.200307Z"}}},{"cell_type":"code","source":"cosine_sim","metadata":{"execution":{"iopub.status.busy":"2021-12-12T16:24:07.374866Z","iopub.execute_input":"2021-12-12T16:24:07.375146Z","iopub.status.idle":"2021-12-12T16:24:07.384545Z","shell.execute_reply.started":"2021-12-12T16:24:07.375114Z","shell.execute_reply":"2021-12-12T16:24:07.383595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"actual_genres = []\npredicted_genres = {}","metadata":{"execution":{"iopub.status.busy":"2021-12-12T16:24:07.385642Z","iopub.execute_input":"2021-12-12T16:24:07.385912Z","iopub.status.idle":"2021-12-12T16:24:07.396992Z","shell.execute_reply.started":"2021-12-12T16:24:07.385883Z","shell.execute_reply":"2021-12-12T16:24:07.396276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_by_idx(idx):\n    actual_genres = []\n    predicted_genres_good = {}\n    predicted_genres_bad = {}\n    print(\"Prediction for movie:\",useful_links_df[\"title\"].iloc[idx], \"\\n \\n\")\n    actual_genres = useful_links_df[\"genres\"].iloc[idx].split(\"|\")\n    similar_movies = list(enumerate(cosine_sim[idx]))\n    sorted_similar_movies = sorted(similar_movies, key=lambda x:x[1], reverse=True)\n    \n    print(\"Predictions \\n \\n\")\n    \n    i = 0\n    for movie_idx in sorted_similar_movies:\n        if i>0:\n            print(useful_links_df[\"title\"].iloc[movie_idx[0]], \"   sim:\", movie_idx[1])\n            predicted_genres_for_movie = useful_links_df[\"genres\"].iloc[movie_idx[0]].split(\"|\")\n            for genre in predicted_genres_for_movie:\n                if genre in actual_genres:\n                    if genre in predicted_genres_good:\n                        predicted_genres_good[genre] =  predicted_genres_good[genre] + 1\n                    else:\n                        predicted_genres_good[genre] = 1\n                else:\n                    if genre in predicted_genres_bad:\n                        predicted_genres_bad[genre] =  predicted_genres_bad[genre] + 1\n                    else:\n                        predicted_genres_bad[genre] = 1\n        i = i + 1\n        if i>20:\n            break\n            \n    print(actual_genres)\n    print(predicted_genres)\n    plt.subplots(figsize=(18,5))\n    plt.bar(predicted_genres_good.keys(), predicted_genres_good.values(), width=0.3, color='g')\n    plt.bar(predicted_genres_bad.keys(), predicted_genres_bad.values(), width=0.3, color='r')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T16:40:45.367133Z","iopub.execute_input":"2021-12-12T16:40:45.367672Z","iopub.status.idle":"2021-12-12T16:40:45.380756Z","shell.execute_reply.started":"2021-12-12T16:40:45.367631Z","shell.execute_reply":"2021-12-12T16:40:45.379706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_by_idx(204)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T16:40:47.730293Z","iopub.execute_input":"2021-12-12T16:40:47.730708Z","iopub.status.idle":"2021-12-12T16:40:47.987525Z","shell.execute_reply.started":"2021-12-12T16:40:47.730676Z","shell.execute_reply":"2021-12-12T16:40:47.98665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the below diagram an example TOP 15 recommendaions can be seen for Star Wars 4 grouped by genre. The green bars represent the genres which is the Star Wars 4.\n\n![](https://i.ibb.co/WsMgzCk/Screenshot-2021-12-12-at-17-41-06.png)\n","metadata":{}},{"cell_type":"markdown","source":"## Conclusion\n\nIt can be seen that for this particular movie, the recommendations are satisfactory. However, like in the CNN case, a clear metric should be defined, and hyperparameter optimalization based on this.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}